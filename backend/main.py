import os
from dotenv import load_dotenv
from openai import OpenAI
import re

from chatbot_faiss_utils import (
    load_paragraphs,
    load_embeddings,
    load_faiss_index
)

# LangChain ìµœì‹  ê¶Œì¥ ë°©ì‹ìœ¼ë¡œ ìˆ˜ì •
from langchain_community.vectorstores import FAISS as LangChainFAISS
from langchain_openai import OpenAIEmbeddings, ChatOpenAI
from langchain.retrievers.multi_query import MultiQueryRetriever
from langchain.retrievers.ensemble import EnsembleRetriever
from langchain_community.retrievers import BM25Retriever
from langchain_core.documents import Document
from langchain_community.document_transformers import LongContextReorder


# í™˜ê²½ ë³€ìˆ˜ ë¡œë“œ ë° í´ë¼ì´ì–¸íŠ¸ ì„¤ì •
load_dotenv()
client = OpenAI(api_key=os.getenv("OPENAI_API_KEY"))

# ë¬¸ì„œ ë¶ˆëŸ¬ì˜¤ê¸°
documents = load_paragraphs("documents.txt")

# BM25 ë¦¬íŠ¸ë¦¬ë²„ìš© ë¬¸ì„œ êµ¬ì„±
bm25_documents = [Document(page_content=doc) for doc in documents]
retriever_bm25 = BM25Retriever.from_documents(bm25_documents)
retriever_bm25.k = 3

# LangChainìš© ë²¡í„°ìŠ¤í† ì–´ ë° ë¦¬íŠ¸ë¦¬ë²„ êµ¬ì„±
embedding_model = OpenAIEmbeddings(
    model="text-embedding-3-small",
    openai_api_key=os.getenv("OPENAI_API_KEY")
)
vectorstore = LangChainFAISS.load_local(
    "index_openai",
    embeddings=embedding_model,
    allow_dangerous_deserialization=True
)
llm = ChatOpenAI(model="gpt-4o", temperature=0.4)

retriever_multi = MultiQueryRetriever.from_llm(
    retriever=vectorstore.as_retriever(search_kwargs={"k": 3}),
    llm=llm
)

retriever = EnsembleRetriever(
    retrievers=[retriever_bm25, retriever_multi],
    weights=[0.4, 0.6]
)

# ì‚¬ìš©ì ì§ˆë¬¸ ì…ë ¥ ë£¨í”„
while True:
    query = input("\nì§ˆë¬¸ ì…ë ¥ (ì¢…ë£Œí•˜ë ¤ë©´ 'exit'): ")
    if query.strip().lower() == "exit":
        break

    # 1. BM25
    docs_bm25 = retriever_bm25.invoke(query)
    print("\nğŸ” [BM25] ì„ íƒëœ ë¬¸ë‹¨:")
    for i, doc in enumerate(docs_bm25):
        print(f"[{i+1}] {doc.page_content[:80]}...")

    # 2. MultiQuery
    docs_multi = retriever_multi.invoke(query)
    print("\nğŸ” [MultiQuery] ì„ íƒëœ ë¬¸ë‹¨:")
    for i, doc in enumerate(docs_multi):
        print(f"[{i+1}] {doc.page_content[:80]}...")

    # 3. ì•™ìƒë¸” ê²°ê³¼
    relevant_docs = retriever.invoke(query)
    print("\nğŸ“„ [Ensemble ê²°ê³¼ ë¬¸ë‹¨]:")
    for i, doc in enumerate(relevant_docs):
        print(f"{i+1}. {doc.page_content[:80]}...")

    # 4. LongContextReorder ì ìš©
    reordering = LongContextReorder()
    reordered_docs = reordering.transform_documents(relevant_docs)
    print("\nğŸ“„ [LongContextReorder ì ìš© ê²°ê³¼]:")
    for i, doc in enumerate(reordered_docs):
        print(f"{i+1}. {doc.page_content[:80]}...")

    # 5. GPT í”„ë¡¬í”„íŠ¸ êµ¬ì„± ì „ì— ì¶œì²˜ ì •ë¦¬
    retrieved_docs = []
    source_pages = []

    for doc in reordered_docs:
        text = doc.page_content
        match = re.search(r"<ì¶œì²˜:\s*(.*?)>", text)
        source = match.group(1).strip() if match else "ì¶œì²˜ ë¯¸ìƒ"
        text_clean = re.sub(r"<ì¶œì²˜:.*?>", "", text).strip()
        retrieved_docs.append(text_clean)
        source_pages.append(source)

    retrieved = "\n\n".join(retrieved_docs)
    unique_sources = sorted(set(source_pages))
    source_note = f"(ìœ„ ë‹µë³€ì€ ìˆ˜ì‹œëª¨ì§‘ìš”ê°• {', '.join(unique_sources)}ì„ ì°¸ê³ í•˜ì—¬ ì‘ì„±ë˜ì—ˆìŠµë‹ˆë‹¤.)"

    # GPT í”„ë¡¬í”„íŠ¸ êµ¬ì„±
    retrieved = "\n\n".join([doc.page_content for doc in reordered_docs])
    prompt = f"""ë„ˆëŠ” ì„±ì‹ ì—¬ìëŒ€í•™êµ ì…ì‹œë¥¼ ì•ˆë‚´í•˜ëŠ” ì±—ë´‡ "ìˆ˜ë£¡ì´"ì•¼.  
ì„±ì‹ ì—¬ëŒ€ë¥¼ ì§€ì›í•˜ë ¤ëŠ” ìˆ˜í—˜ìƒê³¼ í•™ë¶€ëª¨ì—ê²Œ ë¬¸ì„œ ê¸°ë°˜ìœ¼ë¡œ ì¹œì ˆí•˜ê³  ì •í™•í•œ ì •ë³´ë¥¼ ì œê³µí•˜ëŠ” ê²Œ ë„ˆì˜ ì—­í• ì´ì•¼.

[ë¬¸ì„œ ë‚´ìš©]  
{retrieved}

[ì¶œì²˜ ì •ë³´]  
{source_note}

[ì‚¬ìš©ì ì§ˆë¬¸]  
{query}

ë‹¤ìŒ ê¸°ì¤€ì— ë”°ë¼ **í•œêµ­ì–´ë¡œ** ë‹µí•´.

1. ë¬¸ì„œì— ê´€ë ¨ ì •ë³´ê°€ ìˆìœ¼ë©´ ê·¸ ë‚´ìš©ì„ ë°”íƒ•ìœ¼ë¡œ ì •í™•í•˜ê²Œ ë‹µí•´. ê·¼ê±° ì—†ëŠ” ì¶”ì¸¡ì€ í•˜ì§€ ë§ˆ.
2. ë¬¸ì„œì—ì„œ ë‹µì„ ì°¾ì„ ìˆ˜ ì—†ë‹¤ë©´, ë‹¤ìŒ ë¬¸ì¥ì„ ê¼­ í¬í•¨ì‹œì¼œ:  
"ìì„¸í•œ ì‚¬í•­ì€ ì„±ì‹ ì—¬ìëŒ€í•™êµ ì…í•™ì²˜ í™ˆí˜ì´ì§€ì˜ ì…ì‹œìš”ê°•ì„ ì°¸ê³ í•˜ê±°ë‚˜, ì…í•™ì²˜(02-920-2000)ì— ë¬¸ì˜í•´ ì£¼ì„¸ìš”."
3. ì…ì‹œ ì§ˆë¬¸ì´ ì•„ë‹Œ ê²½ìš°ì—ëŠ” ìˆ˜ë£¡ì´ ìºë¦­í„°ë¥¼ ìœ ì§€í•´ì„œ ì§§ê³  ìœ ì¾Œí•˜ê²Œ ìŠ¤ëª°í† í¬í•´.
4. í•­ìƒ ìˆ˜ë£¡ì´ë¼ëŠ” ìºë¦­í„°ì˜ ë§íˆ¬(ì¹œì ˆí•˜ê³  ë˜‘ë˜‘í•œ ìš©)ë¥¼ ìœ ì§€í•´.
5. ë¬¸ì„œì— ì¶œì²˜ê°€ í¬í•¨ë˜ì–´ ìˆì–´ë„, ë‹µë³€ ë³¸ë¬¸ì—ëŠ” ë„£ì§€ ë§ê³ , ë§ˆì§€ë§‰ì— ì•„ë˜ í˜•ì‹ìœ¼ë¡œ í•œ ì¤„ë§Œ ë¶™ì—¬ì¤˜:  
(ìœ„ ë‹µë³€ì€ ìˆ˜ì‹œëª¨ì§‘ìš”ê°• p.16, p.17ì„ ì°¸ê³ í•˜ì—¬ ì‘ì„±ë˜ì—ˆìŠµë‹ˆë‹¤.)
6. ì§ˆë¬¸ì´ ë„ˆë¬´ ì§§ê±°ë‚˜ ë¶ˆë¶„ëª…í•œ ê²½ìš°ì—” ì´ë ‡ê²Œ ë§í•´ì¤˜:  
"ì£„ì†¡í•´ìš”, ì§ˆë¬¸ì´ ì¡°ê¸ˆ ë¶ˆë¶„ëª…í•´ìš”. ì–´ë–¤ ëª¨ì§‘ì— ëŒ€í•´ ê¶ê¸ˆí•˜ì‹ ê°€ìš”? êµ¬ì²´ì ìœ¼ë¡œ ì•Œë ¤ì£¼ì‹œë©´ ë” ì •í™•í•˜ê²Œ ì•ˆë‚´í•´ë“œë¦´ ìˆ˜ ìˆì–´ìš”! ğŸ˜Š"

"""

    chat_response = client.chat.completions.create(
        model="gpt-4o",
        messages=[{"role": "user", "content": prompt}],
        temperature=0.4,
        top_p=0.95,
        presence_penalty=0.6,
        frequency_penalty=0.3
    )

    answer = chat_response.choices[0].message.content
    print("\nğŸ’¬ ìˆ˜ë£¡ì´ì˜ ë‹µë³€:\n" + answer)
